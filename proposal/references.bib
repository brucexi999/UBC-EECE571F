@article{Kahng2022,
   abstract = {The routing process determines the precise signal paths for nets on the chip layout. Routing algorithms often adopt a two-stage approach. Global routing first partitions the chip into routing regions and searches for region-to-region paths for all signal nets; this...},
   author = {Andrew B. Kahng and Jens Lienig and Igor L. Markov and Jin Hu},
   doi = {10.1007/978-3-030-96415-3_5},
   journal = {VLSI Physical Design: From Graph Partitioning to Timing Closure},
   pages = {131-169},
   publisher = {Springer, Cham},
   title = {Global Routing},
   url = {https://link.springer.com/chapter/10.1007/978-3-030-96415-3_5},
   year = {2022},
}
@article{Cheng2021,
   abstract = {For its advantage in GPU acceleration and less dependency on human experts, machine learning has been an emerging tool for solving the placement and routing problems, as two critical steps in modern chip design flow. Being still in its early stage, there are fundamental issues: scalability, reward design, and end-to-end learning paradigm etc. To achieve end-to-end placement learning, we first propose a joint learning method termed by DeepPlace for the placement of macros and standard cells, by the integration of reinforcement learning with a gradient based optimization scheme. To further bridge the placement with the subsequent routing task, we also develop a joint learning approach via reinforcement learning to fulfill both macro placement and routing, which is called DeepPR. One key design in our (reinforcement) learning paradigm involves a multi-view embedding model to encode both global graph level and local node level information of the input macros. Moreover, the random network distillation is devised to encourage exploration. Experiments on public chip design benchmarks show that our method can effectively learn from experience and also provides intermediate placement for the post standard cell placement, within few hours for training.},
   author = {Ruoyu Cheng and Junchi Yan},
   isbn = {9781713845393},
   issn = {10495258},
   journal = {Advances in Neural Information Processing Systems},
   month = {10},
   pages = {16508-16519},
   publisher = {Neural information processing systems foundation},
   title = {On Joint Learning for Solving Placement and Routing in Chip Design},
   volume = {20},
   url = {https://arxiv.org/abs/2111.00234v2},
   year = {2021},
}
@article{Almasan2022,
   abstract = {Deep Reinforcement Learning (DRL) has shown a dramatic improvement in decision-making and automated control problems. Consequently, DRL represents a promising technique to efficiently solve many relevant optimization problems (e.g., routing) in self-driving networks. However, existing DRL-based solutions applied to networking fail to generalize, which means that they are not able to operate properly when applied to network topologies not observed during training. This lack of generalization capability significantly hinders the deployment of DRL technologies in production networks. This is because state-of-the-art DRL-based networking solutions use standard neural networks (e.g., fully connected, convolutional), which are not suited to learn from information structured as graphs. In this paper, we integrate Graph Neural Networks (GNN) into DRL agents and we design a problem specific action space to enable generalization. GNNs are Deep Learning models inherently designed to generalize over graphs of different sizes and structures. This allows the proposed GNN-based DRL agent to learn and generalize over arbitrary network topologies. We test our DRL+GNN agent in a routing optimization use case in optical networks and evaluate it on 180 and 232 unseen synthetic and real-world network topologies respectively. The results show that the DRL+GNN agent is able to outperform state-of-the-art solutions in topologies never seen during training.},
   author = {Paul Almasan and José Suárez-Varela and Krzysztof Rusek and Pere Barlet-Ros and Albert Cabellos-Aparicio},
   doi = {10.1016/J.COMCOM.2022.09.029},
   issn = {0140-3664},
   journal = {Computer Communications},
   keywords = {Deep reinforcement learning,Graph neural networks,Optimization,Routing},
   month = {12},
   pages = {184-194},
   publisher = {Elsevier},
   title = {Deep reinforcement learning meets graph neural networks: Exploring a routing optimization use case},
   volume = {196},
   year = {2022},
}
