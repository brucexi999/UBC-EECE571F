@article{Schulman2017,
   abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
   author = {John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
   month = {7},
   title = {Proximal Policy Optimization Algorithms},
   url = {http://arxiv.org/abs/1707.06347},
   year = {2017},
}
@misc{Wang2018,
   abstract = {We address the problem of learning structured policies for continuous control. In traditional reinforcement learning, policies of agents are learned by multi-layer perceptrons (MLPs) which take the concatenation of all observations from the environment as input for predicting actions. In this work, we propose NerveNet to explicitly model the structure of an agent, which naturally takes the form of a graph. Specifically, serving as the agent's policy network, NerveNet first propagates information over the structure of the agent and then predict actions for different parts of the agent. In the experiments, we first show that our NerveNet is comparable to state-of-the-art methods on standard MuJoCo environments. We further propose our customized reinforcement learning environments for benchmarking two types of structure transfer learning tasks, i.e., size and disability transfer, as well as multi-task learning. We demonstrate that policies learned by NerveNet are significantly more transferable and generalizable than policies learned by other models and are able to transfer even in a zero-shot setting.},
   author = {Tingwu Wang and Renjie Liao and Jimmy Ba and Sanja Fidler},
   title = {NERVENET: LEARNING STRUCTURED POLICY WITH GRAPH NEURAL NETWORKS},
   url = {http://www.cs.toronto.edu/},
   year = {2018},
}
@article{Mirhoseini2021,
   abstract = {Chip floorplanning is the engineering task of designing the physical layout of a computer chip. Despite five decades of research1, chip floorplanning has defied automation, requiring months of intense effort by physical design engineers to produce manufacturable layouts. Here we present a deep reinforcement learning approach to chip floorplanning. In under six hours, our method automatically generates chip floorplans that are superior or comparable to those produced by humans in all key metrics, including power consumption, performance and chip area. To achieve this, we pose chip floorplanning as a reinforcement learning problem, and develop an edge-based graph convolutional neural network architecture capable of learning rich and transferable representations of the chip. As a result, our method utilizes past experience to become better and faster at solving new instances of the problem, allowing chip design to be performed by artificial agents with more experience than any human designer. Our method was used to design the next generation of Google’s artificial intelligence (AI) accelerators, and has the potential to save thousands of hours of human effort for each new generation. Finally, we believe that more powerful AI-designed hardware will fuel advances in AI, creating a symbiotic relationship between the two fields.},
   author = {Azalia Mirhoseini and Anna Goldie and Mustafa Yazgan and Joe Wenjie Jiang and Ebrahim Songhori and Shen Wang and Young Joon Lee and Eric Johnson and Omkar Pathak and Azade Nazi and Jiwoo Pak and Andy Tong and Kavya Srinivasa and William Hang and Emre Tuncer and Quoc V. Le and James Laudon and Richard Ho and Roger Carpenter and Jeff Dean},
   doi = {10.1038/s41586-021-03544-w},
   issn = {14764687},
   issue = {7862},
   journal = {Nature},
   month = {6},
   pages = {207-212},
   pmid = {34108699},
   publisher = {Nature Research},
   title = {A graph placement methodology for fast chip design},
   volume = {594},
   year = {2021},
}
@article{Liao2020,
   abstract = {Global routing has been a historically challenging problem in the electronic circuit design, where the challenge is to connect a large and arbitrary number of circuit components with wires without violating the design rules for the printed circuit boards or integrated circuits. Similar routing problems also exist in the design of complex hydraulic systems, pipe systems, and logistic networks. Existing solutions typically consist of greedy algorithms and hard-coded heuristics. As such, existing approaches suffer from a lack of model flexibility and usually fail to solve sub-problems conjointly. As an alternative approach, this work presents a deep reinforcement learning method for solving the global routing problem in a simulated environment. At the heart of the proposed method is deep reinforcement learning that enables an agent to produce a policy for routing based on the variety of problems, and it is presented with leveraging the conjoint optimization mechanism of deep reinforcement learning. Conjoint optimization mechanism is explained and demonstrated in detail; the best network structure and the parameters of the learned model are explored. Based on the fine-tuned model, routing solutions and rewards are presented and analyzed. The results indicate that the approach can outperform the benchmark method of a sequential A*method, suggesting a promising potential for deep reinforcement learning for global routing and other routing or path planning problems in general. Another major contribution of this work is the development of a global routing problem sets generator with the ability to generate parameterized global routing problem sets with different size and constraints, enabling evaluation of different routing algorithms and the generation of training datasets for future data-driven routing approaches.},
   author = {Haiguang Liao and Wentai Zhang and Xuliang Dong and Barnabas Poczos and Kenji Shimada and Levent Burak Kara},
   doi = {10.1115/1.4045044},
   issn = {10500472},
   issue = {6},
   journal = {Journal of Mechanical Design, Transactions of the ASME},
   keywords = {agent-based design,artificial intelligence,design automation,machine learning},
   month = {6},
   publisher = {American Society of Mechanical Engineers (ASME)},
   title = {A Deep Reinforcement Learning Approach for Global Routing},
   volume = {142},
   year = {2020},
}
@inproceedings{Chen2023,
   abstract = {Detailed routing is the most tedious and complex procedure in design automation and has become a determining factor in layout automation in advanced manufacturing nodes. Despite continuing advances in custom integrated circuit (IC) routing research, industrial custom layout flows remain heavily manual due to the high complexity of the custom IC design problem. Besides conventional design objectives such as wirelength minimization, custom detailed routing must also accommodate additional constraints (e.g., path-matching) across the analog/mixed-signal (AMS) and digital domains, making an already challenging procedure even more so. This paper presents a novel detailed routing framework for custom circuits that leverages deep reinforcement learning to optimize routing patterns while considering custom routing constraints and industrial design rules. Comprehensive post-layout analyses based on industrial designs demonstrate the effectiveness of our framework in dealing with the specified constraints and producing sign-off-quality routing solutions.},
   author = {Hao Chen and Kai Chieh Hsu and Walker J. Turner and Po Hsuan Wei and Keren Zhu and David Z. Pan and Haoxing Ren},
   doi = {10.1145/3569052.3571874},
   isbn = {9781450399784},
   journal = {Proceedings of the International Symposium on Physical Design},
   keywords = {Detailed routing,Full-custom layout,Graph neural networks,Physical design,Reinforcement learning},
   month = {3},
   pages = {26-34},
   publisher = {Association for Computing Machinery},
   title = {Reinforcement Learning Guided Detailed Routing for Custom Circuits},
   year = {2023},
}
@inproceedings{Xie2018,
   abstract = {Early routability prediction helps designers and tools perform preventive measures so that design rule violations can be avoided in a proactive manner. However, it is a huge challenge to have a predictor that is both accurate and fast. In this work, we study how to leverage convolutional neural network to address this challenge. The proposed method, called RouteNet, can either evaluate the overall routability of cell placement solutions without global routing or predict the locations of DRC (Design Rule Checking) hotspots. In both cases, large macros in mixed-size designs are taken into consideration. Experiments on benchmark circuits show that RouteNet can forecast overall routability with accuracy similar to that of global router while using substantially less runtime. For DRC hotspot prediction, RouteNet improves accuracy by 50% compared to global routing. It also significantly outperforms other machine learning approaches such as support vector machine and logistic regression.},
   author = {Zhiyao Xie and Yu Hung Huang and Guan Qi Fang and Haoxing Ren and Shao Yun Fang and Yiran Chen and Jiang Hu},
   doi = {10.1145/3240765.3240843},
   isbn = {9781450359504},
   issn = {10923152},
   journal = {IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD},
   month = {11},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {RouteNet: Routability prediction for mixed-size designs using convolutional neural network},
   year = {2018},
}
@inproceedings{Yue2022,
   abstract = {Chip floorplanning is a complex task within the physical design process, with more than six decades of research dedicated to it. In a recent paper published in Nature∼\citemirhoseini2021graph, a new methodology based on deep reinforcement learning was proposed that solves the floorplanning problem for advanced chip technologies with production quality results. The proposed method enables generalization, which means that the quality of placements improves as the policy is trained on a larger number of chip blocks. In this paper, we describe Circuit Training, an open-source distributed reinforcement learning framework that re-implements the proposed methodology in TensorFlow v2.x. We will explain the framework and discuss ways it can be extended to solve other important problems within physical design and more generally chip design. We also show new experimental results that demonstrate the scaling and generalization performance of Circuit Training.},
   author = {Summer Yue and Ebrahim M. Songhori and Joe Wenjie Jiang and Toby Boyd and Anna Goldie and Azalia Mirhoseini and Sergio Guadarrama},
   doi = {10.1145/3505170.3511478},
   isbn = {9781450392105},
   journal = {Proceedings of the International Symposium on Physical Design},
   keywords = {deep reinforcement learning,distributed deep reinforcement learning,open-source software,transfer learning},
   month = {4},
   pages = {65-70},
   publisher = {Association for Computing Machinery},
   title = {Scalability and Generalization of Circuit Training for Chip Floorplanning},
   year = {2022},
}
@article{Kahng2022,
   abstract = {The routing process determines the precise signal paths for nets on the chip layout. Routing algorithms often adopt a two-stage approach. Global routing first partitions the chip into routing regions and searches for region-to-region paths for all signal nets; this...},
   author = {Andrew B. Kahng and Jens Lienig and Igor L. Markov and Jin Hu},
   doi = {10.1007/978-3-030-96415-3_5},
   journal = {VLSI Physical Design: From Graph Partitioning to Timing Closure},
   pages = {131-169},
   publisher = {Springer, Cham},
   title = {Global Routing},
   url = {https://link.springer.com/chapter/10.1007/978-3-030-96415-3_5},
   year = {2022},
}
@article{Cheng2021,
   abstract = {For its advantage in GPU acceleration and less dependency on human experts, machine learning has been an emerging tool for solving the placement and routing problems, as two critical steps in modern chip design flow. Being still in its early stage, there are fundamental issues: scalability, reward design, and end-to-end learning paradigm etc. To achieve end-to-end placement learning, we first propose a joint learning method termed by DeepPlace for the placement of macros and standard cells, by the integration of reinforcement learning with a gradient based optimization scheme. To further bridge the placement with the subsequent routing task, we also develop a joint learning approach via reinforcement learning to fulfill both macro placement and routing, which is called DeepPR. One key design in our (reinforcement) learning paradigm involves a multi-view embedding model to encode both global graph level and local node level information of the input macros. Moreover, the random network distillation is devised to encourage exploration. Experiments on public chip design benchmarks show that our method can effectively learn from experience and also provides intermediate placement for the post standard cell placement, within few hours for training.},
   author = {Ruoyu Cheng and Junchi Yan},
   isbn = {9781713845393},
   issn = {10495258},
   journal = {Advances in Neural Information Processing Systems},
   month = {10},
   pages = {16508-16519},
   publisher = {Neural information processing systems foundation},
   title = {On Joint Learning for Solving Placement and Routing in Chip Design},
   volume = {20},
   url = {https://arxiv.org/abs/2111.00234v2},
   year = {2021},
}
@article{Almasan2022,
   abstract = {Deep Reinforcement Learning (DRL) has shown a dramatic improvement in decision-making and automated control problems. Consequently, DRL represents a promising technique to efficiently solve many relevant optimization problems (e.g., routing) in self-driving networks. However, existing DRL-based solutions applied to networking fail to generalize, which means that they are not able to operate properly when applied to network topologies not observed during training. This lack of generalization capability significantly hinders the deployment of DRL technologies in production networks. This is because state-of-the-art DRL-based networking solutions use standard neural networks (e.g., fully connected, convolutional), which are not suited to learn from information structured as graphs. In this paper, we integrate Graph Neural Networks (GNN) into DRL agents and we design a problem specific action space to enable generalization. GNNs are Deep Learning models inherently designed to generalize over graphs of different sizes and structures. This allows the proposed GNN-based DRL agent to learn and generalize over arbitrary network topologies. We test our DRL+GNN agent in a routing optimization use case in optical networks and evaluate it on 180 and 232 unseen synthetic and real-world network topologies respectively. The results show that the DRL+GNN agent is able to outperform state-of-the-art solutions in topologies never seen during training.},
   author = {Paul Almasan and José Suárez-Varela and Krzysztof Rusek and Pere Barlet-Ros and Albert Cabellos-Aparicio},
   doi = {10.1016/J.COMCOM.2022.09.029},
   issn = {0140-3664},
   journal = {Computer Communications},
   keywords = {Deep reinforcement learning,Graph neural networks,Optimization,Routing},
   month = {12},
   pages = {184-194},
   publisher = {Elsevier},
   title = {Deep reinforcement learning meets graph neural networks: Exploring a routing optimization use case},
   volume = {196},
   year = {2022},
}
@article{Hu2001,
    abstract = {This paper presents a comprehensive survey on global routing research over about the last two decades, with an emphasis on the problems of simultaneously routing multiple nets in VLSI circuits under various design styles. The survey begins with a coverage of traditional approaches such as sequential routing and rip-up-and-reroute, and then discusses multicommodity flow-based methods, which have attracted a good deal of attention recently. The family of hierarchical routing techniques and several of its variants are then overviewed, in addition to other techniques such as move-based heuristics and iterative deletion. While many traditional techniques focus on the conventional objective of managing congestion, newer objectives have come into play with the advances in VLSI technology. Specifically, the focus of global routing has shifted so that it is important to augment the congestion objective with metrics for timing and crosstalk. In the later part of this paper, we summarize the recent progress in these directions. Finally, the survey concludes with a summary of possible future research directions.[rule] © 2001 Elsevier Science B.V. All rights reserved.},
    author = {Jiang Hu and Sachin S. Sapatnekar},
    doi = {10.1016/S0167-9260(01)00020-7},
    issn = {0167-9260},
    issue = {1},
    journal = {Integration},
    month = {11},
    pages = {1-49},
    publisher = {Elsevier},
    title = {A survey on multi-net global routing for integrated circuits},
    volume = {31},
    year = {2001},
}
@misc{mnih2013playing,
    title={Playing Atari with Deep Reinforcement Learning}, 
    author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
    year={2013},
    eprint={1312.5602},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
